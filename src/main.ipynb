{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Agents\n",
    "The first test is a match between two agents that play 200 random moves each if the game does not end earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_functions import chessboard\n",
    "\n",
    "chessboard_EA = chessboard()\n",
    "for i in range(400):\n",
    "    game_finished = chessboard_EA.random_legal_move()\n",
    "    if game_finished:\n",
    "        break\n",
    "    \n",
    "chessboard_EA.board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stockfish Against a Montecarlo Search Tree Algorithm\n",
    "In the cell below we have a code that simulates a match between the Stockfish Engine and a simple Montecarlo search tree that does not implement any type of intelligence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "from monte_carlo_search_tree import node, MCTS\n",
    "from chess_functions import chessboard, stockfish_eng\n",
    "\n",
    "# chessboard() is a class with some useful functions related to the chessboard. For example with chessboard.board \n",
    "# we can identify the board object.\n",
    "chessboard_EA = chessboard()\n",
    "# Initialization of the stockfish engine later used to pick a move.\n",
    "engine = stockfish_eng()\n",
    "# Initialization of the class that contains the monte-carlo search tree\n",
    "mcts = MCTS()\n",
    "\n",
    "white = 1\n",
    "moves = 0\n",
    "# PGN (Portable Game Notation) is an easy-to-read format which records both the moves of the game \n",
    "# (in standard algebraic notation) and any related data such as the names of the players, the winner/loser, \n",
    "# and even the date the game was played.\n",
    "pgn = []\n",
    "# To export your game with all headers, comments and variations, you can do it like this:\n",
    "game = chess.pgn.Game()\n",
    "\n",
    "i = 0\n",
    "while((not chessboard_EA.board.is_game_over())):\n",
    "    all_moves = [chessboard_EA.board.san(i) for i in list(chessboard_EA.board.legal_moves)]\n",
    "    root = node()\n",
    "    root.state = chessboard_EA.board\n",
    "    \n",
    "    if white:\n",
    "        result = engine.play_best_move(chessboard_EA.board)\n",
    "        print(\"stockfish (white) plays: \", result)\n",
    "    else:\n",
    "        result = mcts.mcts_pred(root, chessboard_EA.board.is_game_over(), white)\n",
    "        print(\"EA (black) plays: \", result)    \n",
    "    \n",
    "    chessboard_EA.board.push_san(result)\n",
    "    \n",
    "    pgn.append(result)\n",
    "    \n",
    "    # the operator ^= Performs Bitwise OR on operands and assign value to left operand. This means that the \n",
    "    # value of white is flipped between 0 and 1 after each move.\n",
    "    white ^= 1\n",
    "    \n",
    "    moves += 1\n",
    "    \n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell if you want to visualize the final position on the board obtained between Stockfish and MCST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboard_EA.board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the EA \n",
    "In the following cell we train the EA and we end-up with a model able to decide the next move to be played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from evaluation_class import evaluator\n",
    "from fitness_function import *\n",
    "from evolutionary_algorithm import genetic_algorithm, Agent_copy\n",
    "import time\n",
    "\n",
    "# Parameter for the training\n",
    "pop_size = 18\n",
    "generations = 6\n",
    "mcst_epochs = 6\n",
    "mcst_depth = 1\n",
    "\n",
    "\n",
    "# We define an object of the class evaluator to generate the model of the NN that evaluates the board.\n",
    "eval_model = evaluator()\n",
    "# Instance of the fitness function, used to define the fitness of the agents.\n",
    "fitness_func = fitness\n",
    "# Core of the code: the evolutionary algorithm that defines the evolution generation after generation.\n",
    "ga = genetic_algorithm()\n",
    "\n",
    "\n",
    "start_time = time.time() # To measure the time needed to train the models.\n",
    "agent, loss = ga.execute(fitness_func, eval_model.simple_eval_model(), pop_size = pop_size, generations = generations, mcst_epochs = mcst_epochs, mcst_depth = mcst_depth)\n",
    "\n",
    "# Updating some information about the set parameters to obtain \"agent\". These are useful for some data analysis and \n",
    "# parameters adjustment later on.\n",
    "agent.training_time = time.time() - start_time\n",
    "agent.pop_size = pop_size\n",
    "agent.generations = generations\n",
    "agent.mcst_epochs = mcst_epochs\n",
    "agent.mcst_depth = mcst_depth\n",
    "agent.description = str(\"This model does not shown any particular skill\")\n",
    "agent.loss_progression = loss\n",
    "\n",
    "# Copying the agent in a format that can be saved by the pickle module in one of the next cells\n",
    "agent_copy = Agent_copy()\n",
    "agent_copy.copy_agent(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fitness score of the agent: \", agent.fitness)\n",
    "print(\"training time in hours: \", agent.training_time/60/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained we can decide if we want to store it in an external file. This can be useful to compare multiple trained agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_filename = \"keras_models/trained_models.pkl\"\n",
    "# set the following variable to True when trained_models.pkl is empty or when you what to delete the content. To \n",
    "# delete the content insert 'yes' when prompt ask if you want to load\n",
    "file_empty = False\n",
    "\n",
    "# if the file is not empty, we load its content into a variable.\n",
    "if file_empty == False:\n",
    "    with open(save_filename, \"rb\") as f:\n",
    "        trained_models = pickle.load(f)\n",
    "    \n",
    "# Thanks to 'load' we can decide whether to load or not the just trained model.\n",
    "load = str(\"no\")\n",
    "load = input(\"\\nUpdate the description of the model!!\\nDo you want to save this model to the external file? \\nyes or no\")\n",
    "\n",
    "if load == \"yes\":\n",
    "    if file_empty:\n",
    "        trained_models = []\n",
    "    else:\n",
    "        trained_models.append(agent_copy)\n",
    "\n",
    "    with open(save_filename, 'wb') as f:\n",
    "        pickle.dump(trained_models, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now estimate the skill level reached by the EA, letting it play against Stockfish. Stockfish is an advanced chess engine that can be regulated in order to obtain up to 21 different skill levels. Notice that already at skill = 0 Stockfish is quite good, it might be considered an ELO = 800/900."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_functions import stockfish_eng\n",
    "engine = stockfish_eng()\n",
    "\n",
    "skill_estimation, board = engine.stockfish_vs_EA(agent, 0, True, 15, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are just tests for future developments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#engine.skill_value(100, skill)\n",
    "limit_strength = {'UCI_LimitStrength': 'true'}\n",
    "# engine.engine._parameters.update(limit_strength)\n",
    "engine.skill_value(0, 0)\n",
    "engine.engine.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "board = chess.Board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = engine.play_best_move(board)\n",
    "board.push_san(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monte_carlo_search_tree import MCTS\n",
    "mcts = MCTS()\n",
    "\n",
    "model = agent.neural_network\n",
    "                    \n",
    "def evaluation(input):\n",
    "    pred = model(input.reshape(1, 8, 8, 12))\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, _ = mcts.simple_mcst(board, evaluation, epochs = mcst_epochs, depth = mcst_depth)  \n",
    "board.push(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push_san('g8f7')\n",
    "#board.pop()\n",
    "#board.legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_functions import stockfish_eng\n",
    "import chess\n",
    "\n",
    "engine_good = stockfish_eng()\n",
    "engine_bad = stockfish_eng()\n",
    "\n",
    "engine_good.skill_value(1350, 20)\n",
    "engine_bad.skill_value(1350, 10)\n",
    "\n",
    "board = chess.Board()\n",
    "\n",
    "while((not board.is_game_over())):   \n",
    "    result = engine_bad.play_best_move(board)\n",
    "    board.push_san(result)\n",
    "    if board.is_game_over():\n",
    "        print(\"engine_bad won\")\n",
    "    \n",
    "    if (not board.is_game_over()):\n",
    "        result = engine_good.play_best_move(board)\n",
    "        board.push_san(result)  \n",
    "        if board.is_game_over():\n",
    "            print(\"engine_good won\")\n",
    "        \n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_bad.engine.get_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing EA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_EA import genetic_algorithm\n",
    "\n",
    "from evaluation_class import evaluator\n",
    "from fitness_function import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Parameter for the training\n",
    "pop_size = 15\n",
    "generations = 8\n",
    "mcst_epochs = 5\n",
    "mcst_depth = 1\n",
    "\n",
    "# We define an object of the class evaluator to generate the model of the NN that evaluates the board.\n",
    "eval_model = evaluator()\n",
    "# Instance of the fitness function, used to define the fitness of the agents.\n",
    "fitness_func = fitness\n",
    "\n",
    "test_EA = genetic_algorithm()\n",
    "test_agents = test_EA.execute(fitness_func, eval_model.simple_eval_model(), pop_size = pop_size, generations = generations, mcst_epochs = mcst_epochs, mcst_depth = mcst_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import clone_model\n",
    "def selection(agents):\n",
    "            # sorting according to the fitness value of the agents, starting from the greater values\n",
    "            agents = sorted(agents, key=lambda agent: agent.fitness, reverse=True)\n",
    "            # printing the fitness of each agent\n",
    "            print(\"The loss of the agents of the previous generation was: \\n\")\n",
    "            print('\\n'.join(map(str, agents)))\n",
    "            # Out of the n agents we keep only 20%, in particular the first 20% of the list where the \n",
    "            # fittest are kept.\n",
    "            agents = agents[:int(0.2 * len(agents))]\n",
    "            \n",
    "            return agents\n",
    "        \n",
    "def reset_fitness(agents):\n",
    "            for agent in agents:\n",
    "                agent.fitness = 100\n",
    "                \n",
    "            return agents\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model):\n",
    "        # clone_model() by keras: Clone a Functional or Sequential Model instance generating new \n",
    "        # random weights.\n",
    "        self.neural_network = clone_model(model)\n",
    "        self.fitness = 100\n",
    "        self.game = None\n",
    "        # The following variables are filled only for the final agent obtained after the training. In \n",
    "        # this way the instance Agent contains all the information to reproduce similar results.\n",
    "        self.training_time = None\n",
    "        self.pop_size = None\n",
    "        self.generations = None\n",
    "        self.mcst_epochs = None\n",
    "        self.mcst_depth = None\n",
    "        \n",
    "        \n",
    "    # The __str__ method is called when the following functions are invoked on the object and \n",
    "    # return a string: print(), str()    \n",
    "    def __str__(self):\n",
    "            return 'Loss: ' + str(self.fitness)\n",
    "\n",
    "    def apply_weights(self, weights):\n",
    "        self.neural_network.set_weights(weights)\n",
    "\n",
    "def unflatten(flattened, shapes):\n",
    "            # \"shapes\" is a list where each element is the shape of a layer of the NN.\n",
    "            # \"flattened\" is a gene sequence of a new offspring. It has to be reordered as list where each \n",
    "            # element is contains the weights of a layer of the model.\n",
    "            new_array = []\n",
    "            index = 0\n",
    "            for shape in shapes:\n",
    "                # \"size\" indicates how many element of \"flattened\" forms a layer of weights for the NN.\n",
    "                size = np.product(shape)\n",
    "                new_array.append(flattened[index : index + size].reshape(shape))\n",
    "                # \"index\" has to be update to select the elements of the next layer\n",
    "                index += size\n",
    "            return np.array(new_array, dtype=object)\n",
    "        \n",
    "def crossover(agents, network, pop_size):\n",
    "            # The agents entering in this function have already been selected, i.e. they are the fittest 20%\n",
    "            # of the previous generation.\n",
    "            offspring = []\n",
    "            \n",
    "            # Given a the population size (pop_size), 80% of the new generation is obtained with crossover. \n",
    "            # Each crossover generates two new agents.\n",
    "            for _ in range((pop_size - len(agents)) // 2):\n",
    "                parent1 = random.choice(agents)\n",
    "                parent2 = random.choice(agents)\n",
    "                # Generation of two new agents, giving as input a blank NN model\n",
    "                child1 = Agent(network)\n",
    "                child2 = Agent(network)\n",
    "                \n",
    "                # get_weights(): Returns the current weights of the layer, as NumPy arrays. \"shapes\" is a list\n",
    "                # where each element is the shape of a layer of the NN.\n",
    "                shapes = [a.shape for a in parent1.neural_network.get_weights()]\n",
    "                # genes1 and genes2 are a long sequence containing the weights of the NN for the parent1 and\n",
    "                # parent2.\n",
    "                genes1 = np.concatenate([a.flatten() for a in parent1.neural_network.get_weights()])\n",
    "                genes2 = np.concatenate([a.flatten() for a in parent2.neural_network.get_weights()])\n",
    "                # Picking a random point to divide the genes between parent1 and parent2\n",
    "                split = random.randint(0, len(genes1)-1)\n",
    "\n",
    "                child1_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())\n",
    "                child2_genes = np.array(genes2[0:split].tolist() + genes1[split:].tolist())\n",
    "                # To use the child_genes as weights of the NN we need to structure them as list where each \n",
    "                # element is contains the weights of a layer of the model. To do so we can exploit the \n",
    "                # function unflatten.\n",
    "                child1_genes = unflatten(child1_genes, shapes)\n",
    "                child2_genes = unflatten(child2_genes, shapes)\n",
    "                \n",
    "                child1.apply_weights(list(child1_genes))\n",
    "                child2.apply_weights(list(child2_genes))\n",
    "                \n",
    "                offspring.append(child1)\n",
    "                offspring.append(child2)\n",
    "            \n",
    "            # The extend() method modifies the original list adding the new elements to the list.\n",
    "            agents.extend(offspring)\n",
    "            # agents now contains the 20% selected + the new crossover agents.\n",
    "            return agents, genes1\n",
    "\n",
    "def mutation(agents):\n",
    "    i = 0\n",
    "    for agent in agents:\n",
    "        # A mutation happens with a 10% probability\n",
    "        if random.uniform(0.0, 1.0) <= 0.1:\n",
    "            print(\"agent \", i)\n",
    "            weights = agent.neural_network.get_weights()\n",
    "            shapes = [a.shape for a in weights]\n",
    "\n",
    "            flattened = np.concatenate([a.flatten() for a in weights])\n",
    "            # selection of a random index for the weights. This index is used to pick the weight to \n",
    "            # mutate.\n",
    "            randint = random.randint(0, len(flattened)-1)\n",
    "            print(\"modified gene: \", randint, flattened[randint])\n",
    "            flattened[randint] = np.random.randn()\n",
    "            print(\"new value: \", flattened[randint])\n",
    "            # print(weights)\n",
    "\n",
    "            new_array = unflatten(flattened, shapes)\n",
    "            agent.apply_weights(new_array)\n",
    "            \n",
    "        i += 1\n",
    "    return agents\n",
    "\n",
    "\n",
    "test_agents[7].fitness = 190\n",
    "test_agents[9].fitness = 200\n",
    "test_agents[12].fitness = 130\n",
    "\n",
    "test_agents_sel = selection(test_agents)\n",
    "test_agents_sel = reset_fitness(test_agents_sel)\n",
    "test_agents_cross, gene1 = crossover(test_agents_sel, eval_model.simple_eval_model(), 5)\n",
    "test_agent_fin = mutation(test_agents_cross)\n",
    "\n",
    "#print(test_agents[7].neural_network.get_weights())\n",
    "# print(\"agent 0: \", test_agents_sel[0].neural_network.get_weights())\n",
    "# print(\"agent 1: \", test_agents_sel[1].neural_network.get_weights())\n",
    "# print(\"agent 2: \", test_agents_sel[2].neural_network.get_weights())\n",
    "\n",
    "# print(\"gene1: \", gene1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_agents_cross))\n",
    "\n",
    "weights = test_agents_cross[0].neural_network.get_weights()\n",
    "shapes = [a.shape for a in weights]\n",
    "\n",
    "flattened = np.concatenate([a.flatten() for a in weights])\n",
    "print(\"prima di mutazione: \", flattened[58])\n",
    "\n",
    "weights1 = test_agent_fin[0].neural_network.get_weights()\n",
    "shapes1 = [a.shape for a in weights1]\n",
    "\n",
    "flattened1 = np.concatenate([a.flatten() for a in weights1])\n",
    "print(\"dopo di mutazione: \", flattened1[58])\n",
    "\n",
    "# print(test_agents_cross[4].neural_network.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33de6d7c653bd6ebe84ba0716ff17716d090f851db904d5d85d0cbc987481696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
